{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fMxD-dwDloHp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-19 15:58:23.520245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow import keras\n",
        "import pickle as pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "IRmTzMSOszqz",
        "outputId": "861a57ef-0859-4d40-cfef-a6517a52be65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature : 0.3625\n",
            "(10000, 8, 8)\n"
          ]
        }
      ],
      "source": [
        "file = open('8x8lattices.pkl','rb')\n",
        "lattice_set = pkl.load(file)\n",
        "\n",
        "t = 0.05 + 5*(2.0/32)\n",
        "print(f'Temperature : {t}')\n",
        "#10k samples each of shape (8,8)\n",
        "lattices = np.array(lattice_set[5])\n",
        "print(lattices.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-19 15:58:51.698880: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 8, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "data = tf.expand_dims(lattices, axis=3)\n",
        "print(data.get_shape())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000\n",
            "(8000, 8, 8, 1) (2000, 8, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "train_split = 0.8\n",
        "size = lattices.shape[0]\n",
        "train_size = int(train_split*size)\n",
        "print(train_size)\n",
        "\n",
        "tf.random.shuffle(data)\n",
        "\n",
        "train_data, val_data = data[:train_size], data[train_size:]\n",
        "print(train_data.get_shape(), val_data.get_shape())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f93NFA0f0vgV"
      },
      "outputs": [],
      "source": [
        "def checkerboard(height, width, reverse=False, dtype=tf.float32):\n",
        "  checkerboard = [[((i % 2) + j) % 2 for j in range(width)] for i in range(height)]\n",
        "  checkerboard = tf.convert_to_tensor(checkerboard, dtype = dtype)\n",
        "  if reverse:\n",
        "      checkerboard = 1 - checkerboard\n",
        "  checkerboard = tf.reshape(checkerboard, (1,height,width,1))\n",
        "  return tf.cast(checkerboard, dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xhWev_c6pEbK"
      },
      "outputs": [],
      "source": [
        "def periodic_padding(x, padding=1):\n",
        "  '''\n",
        "  x: shape (batch_size, d1, d2)\n",
        "  return x padded with periodic boundaries. i.e. torus or donut\n",
        "  '''\n",
        "  d1 = x.shape[1] # dimension 1: height\n",
        "  d2 = x.shape[2] # dimension 2: width\n",
        "  p = padding\n",
        "  # assemble padded x from slices\n",
        "  #            tl,tc,tr\n",
        "  # padded_x = ml,mc,mr\n",
        "  #            bl,bc,br\n",
        "  top_left = x[:, -p:, -p:] # top left\n",
        "  top_center = x[:, -p:, :] # top center\n",
        "  top_right = x[:, -p:, :p] # top right\n",
        "  middle_left = x[:, :, -p:] # middle left\n",
        "  middle_center = x # middle center\n",
        "  middle_right = x[:, :, :p] # middle right\n",
        "  bottom_left = x[:, :p, -p:] # bottom left\n",
        "  bottom_center = x[:, :p, :] # bottom center\n",
        "  bottom_right = x[:, :p, :p] # bottom right\n",
        "  top = tf.concat([top_left, top_center, top_right], axis=2)\n",
        "  middle = tf.concat([middle_left, middle_center, middle_right], axis=2)\n",
        "  bottom = tf.concat([bottom_left, bottom_center, bottom_right], axis=2)\n",
        "  padded_x = tf.concat([top, middle, bottom], axis=1)\n",
        "  return padded_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5tPtTf5G1Byl"
      },
      "outputs": [],
      "source": [
        "filters = 64\n",
        "\n",
        "def Coupling(input_shape):\n",
        "  input = keras.layers.Input(shape=input_shape)\n",
        "\n",
        "  layer1 = keras.layers.Conv2D(filters,3, activation=\"relu\",padding = 'valid',name = 'layer1')(periodic_padding(input))\n",
        "  layer2 = keras.layers.Conv2D(filters,3, activation=\"relu\",padding = 'valid',name = 'layer2')(periodic_padding(layer1))\n",
        "  # layer3 = keras.layers.Conv2D(filters,3, activation=\"relu\",padding = 'valid',name = 'layer3')(periodic_padding(layer2))\n",
        "  # layer4 = keras.layers.Conv2D(filters,3, activation=\"relu\",padding = 'valid',name = 'layer4')(periodic_padding(layer3))\n",
        "  t_layer= keras.layers.Conv2D(1,3,padding = 'valid',name = 't_layer')(periodic_padding(layer2))\n",
        "  s_layer= keras.layers.Conv2D(1,3,activation = 'tanh',padding = 'valid', name = 's_layer')(periodic_padding(layer2)) #tanh prevents exploding gradient\n",
        "\n",
        "  return keras.Model(inputs=input, outputs=[s_layer, t_layer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L_eD5TLw1Cy1"
      },
      "outputs": [],
      "source": [
        "class SimpleNormal:\n",
        "  def __init__(self, loc, var):\n",
        "    self.dist = tfp.distributions.Normal(tf.reshape(loc,(-1,)), tf.reshape(var,(-1,)))\n",
        "    self.shape = loc.shape\n",
        "  def log_prob(self, x):\n",
        "    logp = self.dist.log_prob(tf.reshape(x,(x.shape[0], -1)))\n",
        "    return tf.reduce_sum(logp, axis=1)\n",
        "  def sample_n(self, batch_size , seed = None):\n",
        "    x = self.dist.sample((batch_size,),seed = seed)\n",
        "    return tf.reshape(x,(batch_size, *self.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bRnTpfa71FuV"
      },
      "outputs": [],
      "source": [
        "class RealNVP(keras.Model):\n",
        "  def __init__(self, num_coupling_layers,input_shape,data_constraint):\n",
        "      super().__init__()\n",
        "      self.num_coupling_layers = num_coupling_layers\n",
        "      self.distribution = SimpleNormal(tf.zeros((8,8)), tf.ones((8,8)))\n",
        "      self.masks = [checkerboard(input_shape[0],input_shape[1], reverse=False),checkerboard(input_shape[0],input_shape[1], reverse=True)]*(num_coupling_layers // 2)\n",
        "      self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "      self.layers_list = [Coupling(input_shape) for i in range(num_coupling_layers)]\n",
        "      self.data_constraint = data_constraint\n",
        "\n",
        "  def call(self, x, forward=True):\n",
        "    if forward:\n",
        "      # alpha = tf.constant(self.data_constraint)\n",
        "      logq = self.distribution.log_prob(tf.reshape(x,(-1,8,8)))\n",
        "      x,ldj1 = self.forward_flow(x)\n",
        "      # ldj2 = tf.math.softplus(x) + tf.math.softplus(-x) + tf.math.log(tf.constant(1.-2*self.data_constraint))\n",
        "      # ldj2 = tf.reduce_sum(ldj2,[1,2,3])\n",
        "      logq = logq - ldj1 #+ ldj2\n",
        "      # x   = (tf.math.sigmoid(x) - alpha)/(1-2*alpha)\n",
        "      return x, logq\n",
        "    else:\n",
        "      # added to bring data to range of (-inf,inf) as in gaussian o/w training will be poor\n",
        "      # data constraint is added to keep data from attaining 0 or 1 as then log explodes to inf  \n",
        "      x = self.data_constraint + (1-2*self.data_constraint)*x\n",
        "      x = tf.math.log(x/(1.-x))\n",
        "      # Save log-determinant of Jacobian of initial transform\n",
        "      ldj1 = tf.math.softplus(x) + tf.math.softplus(-x) + tf.math.log(tf.constant(1.-2*self.data_constraint))\n",
        "      ldj1 = tf.reduce_sum(ldj1,[1,2,3])\n",
        "      x,ldj2 = self.reverse_flow(x)\n",
        "      logq = self.distribution.log_prob(tf.reshape(x,(-1,8,8)))\n",
        "      logq = logq + ldj2 #+ ldj1\n",
        "      return x , logq\n",
        "\n",
        "  def forward_flow(self, x):\n",
        "    ldj = 0\n",
        "    for i in range(self.num_coupling_layers):\n",
        "      x_frozen = x * self.masks[i]\n",
        "      reversed_mask = 1 - self.masks[i]\n",
        "      x_active = x * reversed_mask\n",
        "      s, t = self.layers_list[i](x_frozen)\n",
        "      s *= reversed_mask\n",
        "      t *= reversed_mask\n",
        "\n",
        "      fx = t + x_active *tf.exp(s) + x_frozen\n",
        "      ldj += tf.reduce_sum(s, [1,2,3])\n",
        "      x = fx\n",
        "    return x, ldj\n",
        "\n",
        "  def reverse_flow(self, fx):\n",
        "    ldj = 0\n",
        "    for i in reversed(range(self.num_coupling_layers)):\n",
        "      fx_frozen = fx*self.masks[i]\n",
        "      reversed_mask = 1 - self.masks[i]\n",
        "      fx_active = fx*reversed_mask\n",
        "      s, t = self.layers_list[i](fx_frozen)\n",
        "      s *= reversed_mask\n",
        "      t *= reversed_mask\n",
        "\n",
        "      x = (fx_active - t) *tf.exp(-s) + fx_frozen\n",
        "      ldj -= tf.reduce_sum(s, [1,2,3])\n",
        "      fx = x\n",
        "    return fx,ldj\n",
        "\n",
        "  def log_loss(self, x, forward=True):\n",
        "    _, log_likelihood = self(x, forward=forward)\n",
        "    return -tf.reduce_mean(log_likelihood)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WavxC4yclg7N"
      },
      "outputs": [],
      "source": [
        "model = RealNVP(6,(8,8,1),1e-4)\n",
        "optimizer=keras.optimizers.Adam(learning_rate=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "train_batches = tf.data.Dataset.from_tensor_slices(train_data).batch(batch_size)\n",
        "val_batches = tf.data.Dataset.from_tensor_slices(val_data).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-19 16:15:36.138365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [8000,8,8,1]\n",
            "\t [[{{node Placeholder/_0}}]]\n",
            "2023-06-19 16:16:04.998193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [2000,8,8,1]\n",
            "\t [[{{node Placeholder/_0}}]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 train_loss = 75.169 val loss = 55.750\n",
            "Epoch 2 train_loss = 50.590 val loss = 48.788\n",
            "Epoch 3 train_loss = 44.980 val loss = 42.089\n",
            "Epoch 4 train_loss = 39.209 val loss = 44.755\n",
            "Epoch 5 train_loss = 37.997 val loss = 38.208\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "\n",
        "for e in range(epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    for step,t_batch in enumerate(train_batches):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = model.log_loss(t_batch, forward=False)\n",
        "\n",
        "        grad = tape.gradient(loss, model.trainable_variables)  \n",
        "        optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
        "        model.loss_tracker.update_state(loss)  \n",
        "        train_losses.append(loss)\n",
        "    \n",
        "    for _,v_batch in enumerate(val_batches):\n",
        "        loss = model.log_loss(v_batch, forward=False)\n",
        "        val_losses.append(loss)\n",
        "\n",
        "    train_loss = np.mean(np.array(train_losses))\n",
        "    val_loss = np.mean(np.array(val_losses))\n",
        "    print(f'Epoch {e+1} train_loss = {train_loss:.3f} val loss = {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
