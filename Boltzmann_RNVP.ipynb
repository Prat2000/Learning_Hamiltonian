{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow import keras\n",
        "import pickle as pkl"
      ],
      "metadata": {
        "id": "fMxD-dwDloHp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('8x8lattices.pkl','rb')\n",
        "lattice_set = pkl.load(file)\n",
        "\n",
        "t = 0.05 + 5*(2.0/32)\n",
        "print(t)\n",
        "#10k samples each of shape (8,8)\n",
        "lattices = np.array(lattice_set[5])\n",
        "print(lattices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "IRmTzMSOszqz",
        "outputId": "861a57ef-0859-4d40-cfef-a6517a52be65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c578f0ba4ad8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'8x8lattices.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlattice_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: pickle data was truncated"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f93NFA0f0vgV"
      },
      "outputs": [],
      "source": [
        "def checkerboard(height, width, reverse=False, dtype=tf.float32):\n",
        "  checkerboard = [[((i % 2) + j) % 2 for j in range(width)] for i in range(height)]\n",
        "  checkerboard = tf.convert_to_tensor(checkerboard, dtype = dtype)\n",
        "  if reverse:\n",
        "      checkerboard = 1 - checkerboard\n",
        "  checkerboard = tf.reshape(checkerboard, (1,height,width,1))\n",
        "  return tf.cast(checkerboard, dtype=dtype)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def periodic_padding(x, padding=1):\n",
        "  '''\n",
        "  x: shape (batch_size, d1, d2)\n",
        "  return x padded with periodic boundaries. i.e. torus or donut\n",
        "  '''\n",
        "  d1 = x.shape[1] # dimension 1: height\n",
        "  d2 = x.shape[2] # dimension 2: width\n",
        "  p = padding\n",
        "  # assemble padded x from slices\n",
        "  #            tl,tc,tr\n",
        "  # padded_x = ml,mc,mr\n",
        "  #            bl,bc,br\n",
        "  top_left = x[:, -p:, -p:] # top left\n",
        "  top_center = x[:, -p:, :] # top center\n",
        "  top_right = x[:, -p:, :p] # top right\n",
        "  middle_left = x[:, :, -p:] # middle left\n",
        "  middle_center = x # middle center\n",
        "  middle_right = x[:, :, :p] # middle right\n",
        "  bottom_left = x[:, :p, -p:] # bottom left\n",
        "  bottom_center = x[:, :p, :] # bottom center\n",
        "  bottom_right = x[:, :p, :p] # bottom right\n",
        "  top = tf.concat([top_left, top_center, top_right], axis=2)\n",
        "  middle = tf.concat([middle_left, middle_center, middle_right], axis=2)\n",
        "  bottom = tf.concat([bottom_left, bottom_center, bottom_right], axis=2)\n",
        "  padded_x = tf.concat([top, middle, bottom], axis=1)\n",
        "  return padded_x"
      ],
      "metadata": {
        "id": "xhWev_c6pEbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = 64\n",
        "\n",
        "def Coupling(input_shape):\n",
        "  input = keras.layers.Input(shape=input_shape)\n",
        "\n",
        "  layer1 = keras.layers.Conv2D(filters,3, activation=\"relu\",padding = 'valid',name = 'layer1')(periodic_padding(input))\n",
        "  layer2 = keras.layers.Conv2D(filters,3, activation=\"relu\",padding = 'valid',name = 'layer2')(periodic_padding(layer1))\n",
        "  t_layer= keras.layers.Conv2D(1,3,padding = 'valid',name = 't_layer')(periodic_padding(layer2))\n",
        "  s_layer= keras.layers.Conv2D(1,3,activation = 'tanh',padding = 'valid', name = 's_layer')(periodic_padding(layer2))\n",
        "\n",
        "  return keras.Model(inputs=input, outputs=[s_layer, t_layer])"
      ],
      "metadata": {
        "id": "5tPtTf5G1Byl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNormal:\n",
        "  def __init__(self, loc, var):\n",
        "    self.dist = tfp.distributions.Normal(tf.reshape(loc,(-1,)), tf.reshape(var,(-1,)))\n",
        "    self.shape = loc.shape\n",
        "  def log_prob(self, x):\n",
        "    logp = self.dist.log_prob(tf.reshape(x,(x.shape[0], -1)))\n",
        "    return tf.reduce_sum(logp, axis=1)\n",
        "  def sample_n(self, batch_size , seed = None):\n",
        "    x = self.dist.sample((batch_size,),seed = seed)\n",
        "    return tf.reshape(x,(batch_size, *self.shape))"
      ],
      "metadata": {
        "id": "L_eD5TLw1Cy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVP(keras.Model):\n",
        "  def __init__(self, num_coupling_layers,input_shape , data_constraint):\n",
        "      super().__init__()\n",
        "      self.num_coupling_layers = num_coupling_layers\n",
        "      self.distribution = SimpleNormal(tf.zeros((8,8)), tf.ones((8,8)))\n",
        "      self.masks = [checkerboard(input_shape[0],input_shape[1], reverse=False),checkerboard(input_shape[0],input_shape[1], reverse=True)]*(num_coupling_layers // 2)\n",
        "      self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "      self.layers_list = [Coupling(input_shape) for i in range(num_coupling_layers)]\n",
        "      self.data_constraint = data_constraint\n",
        "\n",
        "  def call(self, x, forward=True):\n",
        "    if forward:\n",
        "      alpha = tf.constant(self.data_constraint)\n",
        "      logq = self.distribution.log_prob(tf.reshape(x,(-1,8,8)))\n",
        "      x,ldj1 = self.forward(x)\n",
        "      ldj2 = tf.math.softplus(x) + tf.math.softplus(-x) + tf.math.log(tf.constant(1.-2*self.data_constraint))\n",
        "      ldj2 = tf.reduce_sum(ldj2,[1,2,3])\n",
        "      logq = logq - ldj1 + ldj2\n",
        "      x   = (tf.math.sigmoid(x) - alpha)/(1-2*alpha)\n",
        "      return x, logq\n",
        "    else:\n",
        "      x = self.data_constraint + (1-2*self.data_constraint)*x\n",
        "      x = tf.math.log(x/(1.-x))\n",
        "      # Save log-determinant of Jacobian of initial transform\n",
        "      ldj1 = tf.math.softplus(x) + tf.math.softplus(-x) + tf.math.log(tf.constant(1.-2*self.data_constraint))\n",
        "      ldj1 = tf.reduce_sum(ldj1,[1,2,3])\n",
        "      x,ldj2 = self.reverse(x)\n",
        "      logq = self.distribution.log_prob(tf.reshape(x,(-1,8,8)))\n",
        "      logq = logq + ldj2 + ldj1\n",
        "      return x , logq\n",
        "\n",
        "  def forward(self, x):\n",
        "    ldj = 0\n",
        "    for i in range(self.num_coupling_layers):\n",
        "      x_frozen = x * self.masks[i]\n",
        "      reversed_mask = 1 - self.masks[i]\n",
        "      x_active = x * reversed_mask\n",
        "      s, t = self.layers_list[i](x_frozen)\n",
        "      s *= reversed_mask\n",
        "      t *= reversed_mask\n",
        "\n",
        "      fx = t + x_active *tf.exp(s) + x_frozen\n",
        "      ldj += tf.reduce_sum(s, [1,2,3])\n",
        "      x = fx\n",
        "    return x, ldj\n",
        "\n",
        "  def reverse(self, fx):\n",
        "    ldj = 0\n",
        "    for i in reversed(range(self.num_coupling_layers)):\n",
        "      fx_frozen = fx*self.masks[i]\n",
        "      reversed_mask = 1 - self.masks[i]\n",
        "      fx_active = fx*reversed_mask\n",
        "      s, t = self.layers_list[i](fx_frozen)\n",
        "      s *= reversed_mask\n",
        "      t *= reversed_mask\n",
        "\n",
        "      x = (fx_active - t) *tf.exp(-s) + fx_frozen\n",
        "      ldj -= tf.reduce_sum(s, [1,2,3])\n",
        "      fx = x\n",
        "    return fx,ldj"
      ],
      "metadata": {
        "id": "bRnTpfa71FuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WavxC4yclg7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}